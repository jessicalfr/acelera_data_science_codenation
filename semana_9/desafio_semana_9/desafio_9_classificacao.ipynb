{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 9 - Classificação com os dados do ENEM 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Jéssica Ramos*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A base de dados que será utilizada é a mesma do desafio anterior, porém com um *target* diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13730, 167)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dados de treino\n",
    "treino = pd.read_csv('train.csv')\n",
    "\n",
    "treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4570, 43)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dados de teste\n",
    "teste = pd.read_csv('test.csv')\n",
    "\n",
    "teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo é verificar se existem dados ausentes na coluna do *target*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino['IN_TREINEIRO'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como não há nenhum dado ausente, o segundo passo é selecionar as *features* que serão utilizadas. Como as bases de treino e teste têm número distinto de colunas, serão consideradas apenas as colunas em comum nas duas bases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CO_UF_RESIDENCIA',\n",
       " 'IN_BAIXA_VISAO',\n",
       " 'IN_CEGUEIRA',\n",
       " 'IN_DISCALCULIA',\n",
       " 'IN_DISLEXIA',\n",
       " 'IN_GESTANTE',\n",
       " 'IN_IDOSO',\n",
       " 'IN_SABATISTA',\n",
       " 'IN_SURDEZ',\n",
       " 'NU_IDADE',\n",
       " 'NU_INSCRICAO',\n",
       " 'NU_NOTA_CH',\n",
       " 'NU_NOTA_CN',\n",
       " 'NU_NOTA_COMP1',\n",
       " 'NU_NOTA_COMP2',\n",
       " 'NU_NOTA_COMP3',\n",
       " 'NU_NOTA_COMP4',\n",
       " 'NU_NOTA_COMP5',\n",
       " 'NU_NOTA_LC',\n",
       " 'NU_NOTA_REDACAO',\n",
       " 'Q001',\n",
       " 'Q002',\n",
       " 'Q006',\n",
       " 'Q024',\n",
       " 'Q025',\n",
       " 'Q026',\n",
       " 'Q027',\n",
       " 'Q047',\n",
       " 'SG_UF_RESIDENCIA',\n",
       " 'TP_ANO_CONCLUIU',\n",
       " 'TP_COR_RACA',\n",
       " 'TP_DEPENDENCIA_ADM_ESC',\n",
       " 'TP_ENSINO',\n",
       " 'TP_ESCOLA',\n",
       " 'TP_LINGUA',\n",
       " 'TP_NACIONALIDADE',\n",
       " 'TP_PRESENCA_CH',\n",
       " 'TP_PRESENCA_CN',\n",
       " 'TP_PRESENCA_LC',\n",
       " 'TP_PRESENCA_MT',\n",
       " 'TP_SEXO',\n",
       " 'TP_STATUS_REDACAO',\n",
       " 'TP_ST_CONCLUSAO']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lista as colunas em comum\n",
    "colunas_treino = treino.columns\n",
    "colunas_teste = teste.columns\n",
    "\n",
    "colunas_comum = list(set(colunas_teste).intersection(colunas_treino))\n",
    "colunas_comum.sort()\n",
    "colunas_comum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quantidade de colunas\n",
    "len(colunas_comum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável `NU_INSCRICAO` será removida por se tratar do número de inscrição do aluno. Além disso, a variável `CO_UF_RESIDENCIA` será removida pois contém a mesma informação da variável `SG_UF_RESIDENCIA`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cria lista de features\n",
    "features = colunas_comum.copy()\n",
    "\n",
    "# remove as features citadas\n",
    "features.remove('NU_INSCRICAO')\n",
    "features.remove('CO_UF_RESIDENCIA')\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também serão removidas as variáveis que indicam pedidos de atendimento especializado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove as features de atendimento especializado\n",
    "r1 = ('IN_BAIXA_VISAO', 'IN_CEGUEIRA', 'IN_DISCALCULIA', 'IN_DISLEXIA', 'IN_GESTANTE',\n",
    "      'IN_IDOSO', 'IN_SABATISTA', 'IN_SURDEZ')\n",
    "\n",
    "for elem in r1:\n",
    "    features.remove(elem)\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora é necessário verificar se existem dados ausentes nas features restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13730 entries, 0 to 13729\n",
      "Data columns (total 33 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   NU_IDADE                13730 non-null  int64  \n",
      " 1   NU_NOTA_CH              10341 non-null  float64\n",
      " 2   NU_NOTA_CN              10341 non-null  float64\n",
      " 3   NU_NOTA_COMP1           10133 non-null  float64\n",
      " 4   NU_NOTA_COMP2           10133 non-null  float64\n",
      " 5   NU_NOTA_COMP3           10133 non-null  float64\n",
      " 6   NU_NOTA_COMP4           10133 non-null  float64\n",
      " 7   NU_NOTA_COMP5           10133 non-null  float64\n",
      " 8   NU_NOTA_LC              10133 non-null  float64\n",
      " 9   NU_NOTA_REDACAO         10133 non-null  float64\n",
      " 10  Q001                    13730 non-null  object \n",
      " 11  Q002                    13730 non-null  object \n",
      " 12  Q006                    13730 non-null  object \n",
      " 13  Q024                    13730 non-null  object \n",
      " 14  Q025                    13730 non-null  object \n",
      " 15  Q026                    13730 non-null  object \n",
      " 16  Q027                    6357 non-null   object \n",
      " 17  Q047                    13730 non-null  object \n",
      " 18  SG_UF_RESIDENCIA        13730 non-null  object \n",
      " 19  TP_ANO_CONCLUIU         13730 non-null  int64  \n",
      " 20  TP_COR_RACA             13730 non-null  int64  \n",
      " 21  TP_DEPENDENCIA_ADM_ESC  4282 non-null   float64\n",
      " 22  TP_ENSINO               4282 non-null   float64\n",
      " 23  TP_ESCOLA               13730 non-null  int64  \n",
      " 24  TP_LINGUA               13730 non-null  int64  \n",
      " 25  TP_NACIONALIDADE        13730 non-null  int64  \n",
      " 26  TP_PRESENCA_CH          13730 non-null  int64  \n",
      " 27  TP_PRESENCA_CN          13730 non-null  int64  \n",
      " 28  TP_PRESENCA_LC          13730 non-null  int64  \n",
      " 29  TP_PRESENCA_MT          13730 non-null  int64  \n",
      " 30  TP_SEXO                 13730 non-null  object \n",
      " 31  TP_STATUS_REDACAO       10133 non-null  float64\n",
      " 32  TP_ST_CONCLUSAO         13730 non-null  int64  \n",
      "dtypes: float64(12), int64(11), object(10)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "treino[features].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis `Q027`, `TP_DEPENDENCIA_ADM_ESC` e `TP_ENSINO` contém dados ausentes em mais da metade das observações e, portanto, serão removidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove as features com muitos dados ausentes\n",
    "r2 = ('Q027','TP_DEPENDENCIA_ADM_ESC','TP_ENSINO')\n",
    "\n",
    "for elem in r2:\n",
    "    features.remove(elem)\n",
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis `NU_NOTA_CH`, `NU_NOTA_CN`, `NU_NOTA_COMP1`, `NU_NOTA_COMP2`, `NU_NOTA_COMP3`, `NU_NOTA_COMP4`, `NU_NOTA_COMP5`, `NU_NOTA_LC` e `NU_NOTA_REDACAO` têm alguns dados ausentes. Como são dados de notas, é razoável assumir que o candidato não realizou a prova. Portanto, a nota será substituída pela nota 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NU_NOTA_CH 3389\n",
      "NU_NOTA_CN 3389\n",
      "NU_NOTA_COMP1 3597\n",
      "NU_NOTA_COMP2 3597\n",
      "NU_NOTA_COMP3 3597\n",
      "NU_NOTA_COMP4 3597\n",
      "NU_NOTA_COMP5 3597\n",
      "NU_NOTA_LC 3597\n",
      "NU_NOTA_REDACAO 3597\n"
     ]
    }
   ],
   "source": [
    "# número de NaN\n",
    "i1 = ('NU_NOTA_CH','NU_NOTA_CN','NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP3',\n",
    "      'NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_LC','NU_NOTA_REDACAO')\n",
    "\n",
    "for var in i1:\n",
    "    print(var, treino[var].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitui os NaN por 0\n",
    "for var in i1:\n",
    "    treino[var].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A variável `TP_STATUS_REDACAO` também contém dados ausentes na base de treino. Como se trata de uma variável categórica (não no tipo ainda, mas pela definição do dicionário de variáveis), vamos inserir a categoria 99 que significa que o dado está ausente para aquele candidato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitui NA por 99\n",
    "treino['TP_STATUS_REDACAO'].fillna(99, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é importante verificar os dados ausentes na base de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4570 entries, 0 to 4569\n",
      "Data columns (total 30 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   NU_IDADE           4570 non-null   int64  \n",
      " 1   NU_NOTA_CH         3458 non-null   float64\n",
      " 2   NU_NOTA_CN         3458 non-null   float64\n",
      " 3   NU_NOTA_COMP1      3400 non-null   float64\n",
      " 4   NU_NOTA_COMP2      3400 non-null   float64\n",
      " 5   NU_NOTA_COMP3      3400 non-null   float64\n",
      " 6   NU_NOTA_COMP4      3400 non-null   float64\n",
      " 7   NU_NOTA_COMP5      3400 non-null   float64\n",
      " 8   NU_NOTA_LC         3400 non-null   float64\n",
      " 9   NU_NOTA_REDACAO    3400 non-null   float64\n",
      " 10  Q001               4570 non-null   object \n",
      " 11  Q002               4570 non-null   object \n",
      " 12  Q006               4570 non-null   object \n",
      " 13  Q024               4570 non-null   object \n",
      " 14  Q025               4570 non-null   object \n",
      " 15  Q026               4570 non-null   object \n",
      " 16  Q047               4570 non-null   object \n",
      " 17  SG_UF_RESIDENCIA   4570 non-null   object \n",
      " 18  TP_ANO_CONCLUIU    4570 non-null   int64  \n",
      " 19  TP_COR_RACA        4570 non-null   int64  \n",
      " 20  TP_ESCOLA          4570 non-null   int64  \n",
      " 21  TP_LINGUA          4570 non-null   int64  \n",
      " 22  TP_NACIONALIDADE   4570 non-null   int64  \n",
      " 23  TP_PRESENCA_CH     4570 non-null   int64  \n",
      " 24  TP_PRESENCA_CN     4570 non-null   int64  \n",
      " 25  TP_PRESENCA_LC     4570 non-null   int64  \n",
      " 26  TP_PRESENCA_MT     4570 non-null   int64  \n",
      " 27  TP_SEXO            4570 non-null   object \n",
      " 28  TP_STATUS_REDACAO  3400 non-null   float64\n",
      " 29  TP_ST_CONCLUSAO    4570 non-null   int64  \n",
      "dtypes: float64(10), int64(11), object(9)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "teste[features].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Há dados ausentes nas variáveis de nota e na variável `TP_STATUS_REDACAO`. Portanto, faremos as mesmas substituições que fizemos para essas variáveis na base de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NU_NOTA_CH 1112\n",
      "NU_NOTA_CN 1112\n",
      "NU_NOTA_COMP1 1170\n",
      "NU_NOTA_COMP2 1170\n",
      "NU_NOTA_COMP3 1170\n",
      "NU_NOTA_COMP4 1170\n",
      "NU_NOTA_COMP5 1170\n",
      "NU_NOTA_LC 1170\n",
      "NU_NOTA_REDACAO 1170\n"
     ]
    }
   ],
   "source": [
    "# número de NaN\n",
    "i2 = ('NU_NOTA_CH','NU_NOTA_CN','NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP3',\n",
    "      'NU_NOTA_COMP4','NU_NOTA_COMP5','NU_NOTA_LC','NU_NOTA_REDACAO')\n",
    "\n",
    "for var in i2:\n",
    "    print(var, teste[var].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitui os NaN por 0\n",
    "for var in i2:\n",
    "    teste[var].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# substitui NA por 99\n",
    "teste['TP_STATUS_REDACAO'].fillna(99, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features completas\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após esses ajustes a base final de treino tem 30 features completas. Falta checar se os tipos das variáveis estão corretos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NU_IDADE               int64\n",
       "NU_NOTA_CH           float64\n",
       "NU_NOTA_CN           float64\n",
       "NU_NOTA_COMP1        float64\n",
       "NU_NOTA_COMP2        float64\n",
       "NU_NOTA_COMP3        float64\n",
       "NU_NOTA_COMP4        float64\n",
       "NU_NOTA_COMP5        float64\n",
       "NU_NOTA_LC           float64\n",
       "NU_NOTA_REDACAO      float64\n",
       "Q001                  object\n",
       "Q002                  object\n",
       "Q006                  object\n",
       "Q024                  object\n",
       "Q025                  object\n",
       "Q026                  object\n",
       "Q047                  object\n",
       "SG_UF_RESIDENCIA      object\n",
       "TP_ANO_CONCLUIU        int64\n",
       "TP_COR_RACA            int64\n",
       "TP_ESCOLA              int64\n",
       "TP_LINGUA              int64\n",
       "TP_NACIONALIDADE       int64\n",
       "TP_PRESENCA_CH         int64\n",
       "TP_PRESENCA_CN         int64\n",
       "TP_PRESENCA_LC         int64\n",
       "TP_PRESENCA_MT         int64\n",
       "TP_SEXO               object\n",
       "TP_STATUS_REDACAO    float64\n",
       "TP_ST_CONCLUSAO        int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treino[features].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As variáveis `TP_ANO_CONCLUIU`, `TP_COR_RACA`, `TP_ESCOLA`, `TP_NACIONALIDADE`, `TP_PRESENCA_CH`, `TP_PRESENCA_CN`, `TP_PRESENCA_LC`, `TP_PRESENCA_MT`, `TP_STATUS_REDACAO` e `TP_ST_CONCLUSAO` são, na verdade, variáveis categóricas que estão codificadas como números inteiros/float. Dessa forma, é necessário transformar o tipo da coluna para object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajusta o tipo para object\n",
    "objs = ('TP_ANO_CONCLUIU','TP_COR_RACA','TP_ESCOLA','TP_NACIONALIDADE','TP_PRESENCA_CH', 'TP_PRESENCA_CN',\n",
    "        'TP_PRESENCA_LC','TP_PRESENCA_MT','TP_STATUS_REDACAO','TP_ST_CONCLUSAO')\n",
    "\n",
    "for var in objs:\n",
    "    treino[var] = treino[var].astype('category')\n",
    "    teste[var] = teste[var].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demais variáveis que são categóricas na definição só contém duas categorias: 0 e 1. Dessa forma, não é necessário transformar em `object` para depois fazer *one-hot encoding*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de iniciar o ajuste do modelo, é preciso separar as bases, fazer *one-hot encoding* nos dados categóricos e reescalar as variáveis numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treino = pd.get_dummies(treino[features])\n",
    "y_treino = treino['IN_TREINEIRO']\n",
    "\n",
    "# separa as features de teste e o número de inscrição\n",
    "x_teste = pd.get_dummies(teste[features])\n",
    "inscricao_teste = teste['NU_INSCRICAO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13730, 140)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formato da base de treino após one-hot encoding\n",
    "x_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4570, 138)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# formato da base de teste após one-hot encoding\n",
    "x_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem duas variáveis a menos na base de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['TP_PRESENCA_CH_2', 'TP_PRESENCA_CN_2'], dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diferenças entre as bases de treino e teste\n",
    "x_treino.columns.difference(x_teste.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isso ocorreu pois não existem entradas com código 2 para as variáveis `TP_PRESENCA_CH` e `TP_PRESENCA_CN` na base de treino. Isso será corrigido adicionando essas colunas e preenchendo com zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cria as colunas que faltam\n",
    "x_teste['TP_PRESENCA_CH_2'] = 0\n",
    "x_teste['TP_PRESENCA_CN_2'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4570, 140)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_teste.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora falta reescalar as variáveis numéricas. As variáveis com valores destoantes são as variáveis de nota. Sabemos que, para as provas, a nota máxima é 1000 e a nota mínima é 0. Portanto usaremos esses limites para reescalar as variáveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reescala as variáveis de notas de provas\n",
    "v1 = ('NU_NOTA_CN','NU_NOTA_CH','NU_NOTA_LC','NU_NOTA_REDACAO')\n",
    "\n",
    "for var in v1:\n",
    "    x_treino[var] = x_treino[var]/1000\n",
    "    x_teste[var] = x_teste[var]/1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para as colunas de competência a nota máxima é 200 e a nota mínima é 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reescala as variáveis de notas de competências\n",
    "v2 = ('NU_NOTA_COMP1','NU_NOTA_COMP2','NU_NOTA_COMP3','NU_NOTA_COMP4','NU_NOTA_COMP5')\n",
    "\n",
    "for var in v2:\n",
    "    x_treino[var] = x_treino[var]/200\n",
    "    x_teste[var] = x_teste[var]/200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Des)balanceamento da base de treino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de inciar o ajuste de modelos, vamos verificar o (des)balanceamento da base de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.870138\n",
       "1    0.129862\n",
       "Name: IN_TREINEIRO, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treino.value_counts()/y_treino.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver acima que apenas 13% da base fez o ENEM como treineiro, o que significa que a base é desbalanceada. Portanto, utilizaremos o SMOTE para corrigir o desbalanceamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corrigindo o desbalanceamento da base\n",
    "smote = SMOTE()\n",
    "x_treino_smote, y_treino_smote = smote.fit_resample(x_treino, y_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23894, 140)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tamanho da base corrigida\n",
    "x_treino_smote.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: IN_TREINEIRO, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proporção da resposta na nova base\n",
    "y_treino_smote.value_counts()/y_treino_smote.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após a correção do desbalanceamento com o método de *oversampling* podemos ajustar os modelos de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Logístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro modelo que ajustaremos para esse problema será o modelo logístico. Ele é um modelo mais simples e facilmente interpretável."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste do modelo logístico\n",
    "modelo_logistico = LogisticRegression(max_iter=1000) # aumentei o número de iterações para convergência\n",
    "\n",
    "# faz o ajuste por cross-validarion\n",
    "acuracia_logistico = cross_val_score(modelo_logistico, x_treino_smote, y_treino_smote, cv=5, scoring='accuracy')\n",
    "sensib_logistico = cross_val_score(modelo_logistico, x_treino_smote, y_treino_smote, cv=5, scoring='recall')\n",
    "especif_logistico = cross_val_score(modelo_logistico, x_treino_smote, y_treino_smote, cv=5, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo logístico:  0.9970286145320969\n",
      "Sensibilidade do modelo logístico:  0.9965676015069066\n",
      "Especificidade do modelo logístico:  0.9974911797640683\n"
     ]
    }
   ],
   "source": [
    "# imprime a média das estimativas por cross-validation\n",
    "print('Acurácia do modelo logístico: ', acuracia_logistico.mean())\n",
    "print('Sensibilidade do modelo logístico: ', sensib_logistico.mean())\n",
    "print('Especificidade do modelo logístico: ', especif_logistico.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acima é possível ver os resultados por *cross-validation* para o modelo logístico. Tanto a sensibilidade quanto a especificidade do modelo são altas, o que é um bom resultado.\n",
    "\n",
    "É importante lembrar que a acurácia calculada ali dá o mesmo peso para a sensibilidade e para a especificidade, pois a base que utilizamos foi corrigida pelo método SMOTE. No mundo real tem-se mais peso na especificidade do que na sensibilidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faz o fit com todos os dados\n",
    "modelo_logistico.fit(x_treino_smote, y_treino_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Árvore de decisão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como uma segunda tentativa, será ajustada uma árvore de decisão para o problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste da árvore de decisão\n",
    "arvore_decisao = DecisionTreeClassifier(min_samples_split = 10) # cada folha deve ter pelo menos 10 observações\n",
    "\n",
    "# faz o ajuste por cross-validation\n",
    "acuracia_arvore = cross_val_score(arvore_decisao, x_treino_smote, y_treino_smote, cv=5, scoring='accuracy')\n",
    "sensib_arvore = cross_val_score(arvore_decisao, x_treino_smote, y_treino_smote, cv=5, scoring='recall')\n",
    "especif_arvore = cross_val_score(arvore_decisao, x_treino_smote, y_treino_smote, cv=5, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia da árvore de decisão:  0.995982326753777\n",
      "Sensibilidade da árvore de decisão:  0.9955630671260012\n",
      "Especificidade da árvore de decisão:  0.9963200585348723\n"
     ]
    }
   ],
   "source": [
    "# imprime a média das estimativas por cross-validation\n",
    "print('Acurácia da árvore de decisão: ', acuracia_arvore.mean())\n",
    "print('Sensibilidade da árvore de decisão: ', sensib_arvore.mean())\n",
    "print('Especificidade da árvore de decisão: ', especif_arvore.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As métricas da árvore de decisão também são muito boas, parecidas com as do modelo logístico. Até este momento, a escolha de melhor modelo seria do modelo logístico pela simplicidade e pelas métricas um pouquinho melhores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Será feita também uma tentativa de *Random Forest*, que é um algoritmo mais robusto que utiliza a técnica de *bagging*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste da random forest\n",
    "random_forest = RandomForestClassifier(n_estimators=500) # criando 500 árvores de decisão\n",
    "\n",
    "# faz o ajuste por cross-validation\n",
    "acuracia_rf = cross_val_score(random_forest, x_treino_smote, y_treino_smote, cv=5, scoring='accuracy')\n",
    "sensib_rf = cross_val_score(random_forest, x_treino_smote, y_treino_smote, cv=5, scoring='recall')\n",
    "especif_rf = cross_val_score(random_forest, x_treino_smote, y_treino_smote, cv=5, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia da random forest:  0.9979493179969469\n",
      "Sensibilidade da random forest:  0.9973210898627076\n",
      "Especificidade da random forest:  0.9989134970300796\n"
     ]
    }
   ],
   "source": [
    "# imprime a média das estimativas por cross-validation\n",
    "print('Acurácia da random forest: ', acuracia_rf.mean())\n",
    "print('Sensibilidade da random forest: ', sensib_rf.mean())\n",
    "print('Especificidade da random forest: ', especif_rf.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados da *random forest* foram ainda melhores do que os do modelo logístico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=500,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faz o fit com todos os dados\n",
    "random_forest.fit(x_treino_smote, y_treino_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, uma tentativa de ajuste de um *Gradient Boosting Classifier*, que é um algoritmo de *boosting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajuste do GBM\n",
    "gbm = GradientBoostingClassifier()\n",
    "\n",
    "# faz o ajuste por cross-validation\n",
    "acuracia_gbm = cross_val_score(gbm, x_treino_smote, y_treino_smote, cv=5, scoring='accuracy')\n",
    "sensib_gbm = cross_val_score(gbm, x_treino_smote, y_treino_smote, cv=5, scoring='recall')\n",
    "especif_gbm = cross_val_score(gbm, x_treino_smote, y_treino_smote, cv=5, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do GBM:  0.9969449237722137\n",
      "Sensibilidade do GBM:  0.9953958432214595\n",
      "Especificidade do GBM:  0.998492126501221\n"
     ]
    }
   ],
   "source": [
    "# imprime a média das estimativas por cross-validation\n",
    "print('Acurácia do GBM: ', acuracia_gbm.mean())\n",
    "print('Sensibilidade do GBM: ', sensib_gbm.mean())\n",
    "print('Especificidade do GBM: ', especif_gbm.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os resultados do GBM também são muito bons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,\n",
       "                           learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "                           max_features=None, max_leaf_nodes=None,\n",
       "                           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                           min_samples_leaf=1, min_samples_split=2,\n",
       "                           min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                           n_iter_no_change=None, presort='deprecated',\n",
       "                           random_state=None, subsample=1.0, tol=0.0001,\n",
       "                           validation_fraction=0.1, verbose=0,\n",
       "                           warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faz o fit com todos os dados\n",
    "gbm.fit(x_treino_smote, y_treino_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultado final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui serão calculadas as predições para os modelos *random forest* e GBM, que foram os que apresentaram os melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>IN_TREINEIRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ba0cc30ba34e7a46764c09dfc38ed83d15828897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177f281c68fa032aedbd842a745da68490926cd2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6cf0d8b97597d7625cdedc7bdb6c0f052286c334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c356d810fa57671402502cd0933e5601a2ebf1e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df47c07bd881c2db3f38c6048bf77c132ad0ceb3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               NU_INSCRICAO  IN_TREINEIRO\n",
       "0  ba0cc30ba34e7a46764c09dfc38ed83d15828897             0\n",
       "1  177f281c68fa032aedbd842a745da68490926cd2             0\n",
       "2  6cf0d8b97597d7625cdedc7bdb6c0f052286c334             0\n",
       "3  5c356d810fa57671402502cd0933e5601a2ebf1e             0\n",
       "4  df47c07bd881c2db3f38c6048bf77c132ad0ceb3             0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcula as predições da random forest na base de teste\n",
    "y_rf_pred_teste = random_forest.predict(x_teste)\n",
    "\n",
    "resultado_rf = pd.DataFrame({'NU_INSCRICAO': inscricao_teste, 'IN_TREINEIRO': y_rf_pred_teste})\n",
    "resultado_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4570\n",
       "Name: IN_TREINEIRO, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classificações na base de teste\n",
    "resultado_rf['IN_TREINEIRO'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo do *random forest* classifica todas as observações de teste como não-treineiros. Esse não é um bom resultado, pois pode significar *overfitting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>IN_TREINEIRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ba0cc30ba34e7a46764c09dfc38ed83d15828897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177f281c68fa032aedbd842a745da68490926cd2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6cf0d8b97597d7625cdedc7bdb6c0f052286c334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c356d810fa57671402502cd0933e5601a2ebf1e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df47c07bd881c2db3f38c6048bf77c132ad0ceb3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               NU_INSCRICAO  IN_TREINEIRO\n",
       "0  ba0cc30ba34e7a46764c09dfc38ed83d15828897             0\n",
       "1  177f281c68fa032aedbd842a745da68490926cd2             0\n",
       "2  6cf0d8b97597d7625cdedc7bdb6c0f052286c334             0\n",
       "3  5c356d810fa57671402502cd0933e5601a2ebf1e             0\n",
       "4  df47c07bd881c2db3f38c6048bf77c132ad0ceb3             0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcula as predições do GBM na base de teste\n",
    "y_gbm_pred_teste = gbm.predict(x_teste)\n",
    "\n",
    "resultado_gbm = pd.DataFrame({'NU_INSCRICAO': inscricao_teste, 'IN_TREINEIRO': y_gbm_pred_teste})\n",
    "resultado_gbm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4570\n",
       "Name: IN_TREINEIRO, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classificações na base de teste\n",
    "resultado_gbm['IN_TREINEIRO'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo do GBM também classificou todas as observações como não-treineiros. Portanto, vamos utilizar as predições do modelo logístico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NU_INSCRICAO</th>\n",
       "      <th>IN_TREINEIRO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ba0cc30ba34e7a46764c09dfc38ed83d15828897</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177f281c68fa032aedbd842a745da68490926cd2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6cf0d8b97597d7625cdedc7bdb6c0f052286c334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5c356d810fa57671402502cd0933e5601a2ebf1e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df47c07bd881c2db3f38c6048bf77c132ad0ceb3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               NU_INSCRICAO  IN_TREINEIRO\n",
       "0  ba0cc30ba34e7a46764c09dfc38ed83d15828897             0\n",
       "1  177f281c68fa032aedbd842a745da68490926cd2             0\n",
       "2  6cf0d8b97597d7625cdedc7bdb6c0f052286c334             0\n",
       "3  5c356d810fa57671402502cd0933e5601a2ebf1e             0\n",
       "4  df47c07bd881c2db3f38c6048bf77c132ad0ceb3             0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcula as predições do modelo logístico na base de teste\n",
    "y_logistico_pred_teste = modelo_logistico.predict(x_teste)\n",
    "\n",
    "resultado_logistico = pd.DataFrame({'NU_INSCRICAO': inscricao_teste, 'IN_TREINEIRO': y_logistico_pred_teste})\n",
    "resultado_logistico.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4367\n",
       "1     203\n",
       "Name: IN_TREINEIRO, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classificações na base de teste\n",
    "resultado_logistico['IN_TREINEIRO'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo logístico classifica 203 observações da base de teste como treineiros (4,4% da base)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# salva a base de resultados\n",
    "resultado_logistico.to_csv('answer.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
